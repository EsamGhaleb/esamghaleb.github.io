<!DOCTYPE html> <html lang="en"> <head> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title>AI for Healthcare | Esam Ghaleb</title> <meta name="author" content="Esam Ghaleb"/> <meta name="description" content="PeRsOnalized Integrated CARE Solution for Elderly facing several short or long term conditions and enabling a better quality of LIFE (PROCare4Life)"/> <link href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/css/bootstrap.min.css" rel="stylesheet" integrity="sha256-DF7Zhf293AJxJNTmh5zhoYYIMs2oXitRfBjY+9L//AY=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"/> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/@fortawesome/fontawesome-free@5.15.4/css/all.min.css" integrity="sha256-mUZM63G8m73Mcidfrv5E+Y61y7a12O5mW4ezU3bxqW4=" crossorigin="anonymous"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/academicons@1.9.1/css/academicons.min.css" integrity="sha256-i1+4qU2G2860dGGIOJscdC30s9beBXjFfzjWLjBRsBg=" crossorigin="anonymous"> <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/github.css" media="" id="highlight_theme_light"/> <link rel="shortcut icon" href="/assets/img/Esam%20Ghaleb.png"/> <link rel="stylesheet" href="/assets/css/main.css"> <link rel="canonical" href="https://esamghaleb.github.io/projects/04-PROCare4Life/"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jwarby/jekyll-pygments-themes@master/native.css" media="none" id="highlight_theme_dark"/> <script src="/assets/js/theme.js"></script> <script src="/assets/js/dark_mode.js"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-1SQB2F51BX"></script> <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-1SQB2F51BX");</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/">Esam Ghaleb</a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">About</a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">CV</a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">Publications</a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">Teaching and Supervision</a> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="fas fa-moon"></i> <i class="fas fa-sun"></i> </button> </li> </ul> </div> </div> </nav> </header> <div class="container mt-5"> <div class="post"> <header class="post-header"> <h1 class="post-title">AI for Healthcare</h1> <p class="post-description">PeRsOnalized Integrated CARE Solution for Elderly facing several short or long term conditions and enabling a better quality of LIFE (PROCare4Life)</p> </header> <article> <div class="row"> <div class="col-sm mt-3 mt-md-0"> <figure> <picture> <img src="/assets/img/PROCare4Life_logo.png" class="img-fluid rounded z-depth-1" width="auto" height="auto" title="example image" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> </div> </div> <div class="caption"> </div> <p>Besides my research work as a postdoctoral researcher at Maastricht University, I also work for the H2020 European project, <a href="https://procare4life.eu/" target="_blank" rel="noopener noreferrer">PROCareLife</a>. PROCare4Life is an e-health care platform that aims to provide an integrated e-health care monitoring system for seniors with neurodegenerative diseases. In PROCare4Life, my research aims to develop a personalized and dynamic multimodal fusion of behaviors based on data collected from patient symptoms, activities, cognitive abilities, and health records. The multimodal fusion integrates domain knowledge of socio-health professionals into Bayesian Networks to develop a personalized decision support system, improving patients’ quality of life by detecting deviations in their routines and health conditions. Please check the <a href="https://procare4life.eu/" target="_blank" rel="noopener noreferrer">PROCare4Life</a> website for more information. In this project, I also carried out administrative tasks, where I led the WP3 under the Supervision of Dr. Stelios Asteriadis between 2020 and 2021.</p> <p>WP3 is responsible for the sensorial ecosystem of PROCare4life. Sensory tracking acquires data through sensors from wristbands, mobile phones, binary object sensors, and cameras. In particular, these sensors gather various raw measurements, such as heart rate, number of sleeping hours, number of steps, accelerometers, gyroscopes, and human-body trajectories. As part of the sensorial ecosystem of PROCare4Life, Sensory Data Tracking (SDT) was developed to enable the tracking and gathering of sensorial data from different users. Using sensory monitoring, PROCare4Life learns of users’ behavioral habits and detects disease-specific symptoms, e.g., freezing, festination, loss of balance, wandering, confusion, and falls. An essential component of PROCare4Life is the sensorial ecosystem, which provides the necessary tools and modules to track disease progression and facilitate communication between patients with neurodegenerative diseases and the corresponding social and health professionals.</p> <p>In addition, I worked on the multimodal fusion task, where I developed a novel framework that focuses on improving the socio-health care of people with AD and PD. The framework uses human activity recognition algorithms to monitor patients’ physical activities, sleep patterns, and medication intake. It utilizes patients’ socio-demographic data and health records to provide personalized socio-health care. Subsequently, the proposed framework generates high-level representations of diseases’ symptoms, physical activities, sleep patterns, medication intake, cognitive states, comorbidities, and socio-demographic information, health records. The obtained representations are considered scores generated from analyzing long-term patterns of routines and symptoms. The paper presents the multimodal fusion approach of the proposed framework, which aims to utilize the modalities (scores) to detect deviations in patients’ regular routines. The multimodal fusion integrates the domain knowledge of clinical professionals into Bayesian networks, utilizing domain knowledge for the modeling and representation of data. The multimodal fusion generates probabilities of the detected deviations in the patient’s conditions concerning sleep, motor functions, physical activity, and cognitive abilities.</p> <p>Please check the current output of the work on this project in the following items:</p> <ul> <li>Esam Ghaleb, Yusuf Can Semerci, and Stylianos Asteriadis. 2022. <a href="https://www.researchgate.net/profile/Esam-Ghaleb-2/publication/361914581_Modelling_Behaviours_of_People_Living_with_Neurodegenerative_Conditions/links/63173f97acd814437f0a6bc1/Modelling-Behaviours-of-People-Living-with-Neurodegenerative-Conditions.pdf" target="_blank" rel="noopener noreferrer">Modelling Behaviours of People Living with Neurodegenerative Conditions</a>. In Proceedings of the 15th International Conference on PErvasive Technologies Related to Assistive Environments (PETRA ‘22). Association for Computing Machinery, New York, NY, USA, 351–357. https://doi.org/10.1145/3529190.3534721</li> <li>Esam Ghaleb &amp; others. Personalized and Dynamic Multimodal Fusion of Behavioural Analysis of People Living with Neurodegenerative Conditions (under submission).</li> <li>Blog Post: <a href="https://procare4life.eu/news/procare4life-sensorial-ecosystem/" target="_blank" rel="noopener noreferrer">PROCare4Life Sensorial Ecosystem</a> </li> </ul> </article> <h2>Related Publications</h2> <div class="publications"> <ol class="bibliography"><li> <div class="row"> <div class="col-sm-2 preview"><img class="preview z-depth-1 rounded" src="/assets/img/publication_preview/acii2019.png"></div> <div id="ghaleb2019multimodal" class="col-sm-8"> <div class="title">Multimodal and temporal perception of audio-visual cues for emotion recognition</div> <div class="author"> Esam Ghaleb, Mirela Popa, and Stylianos Asteriadis</div> <div class="periodical"> <em>In 2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII)</em> 2019 </div> <div class="links"> <a class="abstract btn btn-sm z-depth-0" role="button">Abs</a> <a class="bibtex btn btn-sm z-depth-0" role="button">Bib</a> <a href="https://ieeexplore.ieee.org/document/8925444" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">HTML</a> <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8925444&amp;casa_token=BELmMn5iqF4AAAAA:BLQxcnLRxrzEnmE2k3C9IFJocmCaj33h2DGrLonDWlavmJtP7yNUcEBHSFedNxdwHHyNvQE" class="btn btn-sm z-depth-0" role="button" target="_blank" rel="noopener noreferrer">PDF</a> </div> <div class="abstract hidden"> <p>In Audio-Video Emotion Recognition (AVER), the idea is to have a human-level understanding of emotions from video clips. There is a need to bring these two modalities into a unified framework, to effectively learn multimodal fusion for AVER. In addition, literature studies lack in-depth analysis and utilization of how emotions vary as a function of time. Psychological and neurological studies show that negative and positive emotions are not recognized at the same speed. In this paper, we propose a novel multimodal temporal deep network framework that embeds video clips using their audio-visual content, onto a metric space, where their gap is reduced and their complementary and supplementary information is explored. We address two research questions, (1) how audio-visual cues contribute to emotion recognition and (2) how temporal information impacts the recognition rate and speed of emotions. The proposed method is evaluated on two datasets, CREMA-D and RAVDESS. The study findings are promising, achieving the state-of-the-art performance on both datasets, and showing a significant impact of multimodal and temporal emotion perception.</p> </div> <div class="bibtex hidden"> <figure class="highlight"><pre><code class="language-bibtex" data-lang="bibtex"><span class="nc">@inproceedings</span><span class="p">{</span><span class="nl">ghaleb2019multimodal</span><span class="p">,</span>
  <span class="na">title</span> <span class="p">=</span> <span class="s">{Multimodal and temporal perception of audio-visual cues for emotion recognition}</span><span class="p">,</span>
  <span class="na">author</span> <span class="p">=</span> <span class="s">{Ghaleb, Esam and Popa, Mirela and Asteriadis, Stylianos}</span><span class="p">,</span>
  <span class="na">booktitle</span> <span class="p">=</span> <span class="s">{2019 8th International Conference on Affective Computing and Intelligent Interaction (ACII)}</span><span class="p">,</span>
  <span class="na">pages</span> <span class="p">=</span> <span class="s">{552--558}</span><span class="p">,</span>
  <span class="na">year</span> <span class="p">=</span> <span class="s">{2019}</span><span class="p">,</span>
  <span class="na">organization</span> <span class="p">=</span> <span class="s">{IEEE}</span><span class="p">,</span>
<span class="p">}</span></code></pre></figure> </div> </div> </div> </li></ol> </div> </div> </div> <footer class="fixed-bottom"> <div class="container mt-0"> © Copyright 2025 Esam Ghaleb. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="noopener noreferrer">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" target="_blank" rel="noopener noreferrer">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="noopener noreferrer">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.bundle.min.js" integrity="sha256-fgLAgv7fyCGopR/gBNq2iW3ZKIdqIcyshnUULC4vex8=" crossorigin="anonymous"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@4/imagesloaded.pkgd.min.js"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.0.6/dist/medium-zoom.min.js" integrity="sha256-EdPgYcPk/IIrw7FYeuJQexva49pVRZNmt3LculEr7zM=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js"></script> <script defer src="/assets/js/common.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.0/es5/tex-mml-chtml.js"></script> <script defer src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-1SQB2F51BX"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-1SQB2F51BX");</script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-1SQB2F51BX"></script> <script>function gtag(){dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-1SQB2F51BX");</script> </body> </html>